# ===============================================================
# Leakage-free synthetic maintenance logs (reviewer-compliant)
# - No same-time target usage
# - Enforces Î” â‰¥ h   (LAG_STEPS >= HORIZON_STEPS)
# - Causal triggers from past-only signals
# - Explicit timing: EventDetectedAt (t-Î”), AvailableToModelAt (t)
# - Scale-aware option for generation drops (relative change)
# ===============================================================

import os
import random
from datetime import timedelta
import numpy as np
import pandas as pd

# -------------------- CONFIG --------------------
MERGED_FILE = r"/home/jyko/ë‹¤ìš´ë¡œë“œ/Raj Kumar/UNISOLAR Solar Power Generation Dataset/Merged_Solar_Weather.csv"

DATA_FREQ_MINUTES   = 15       # 60 if hourly data
HORIZON_STEPS       = 4        # forecast horizon h (steps) e.g., 1 hour ahead @15-min data
LAG_STEPS           = 4        # Î” steps for causal triggers; REQUIRE Î” â‰¥ h
assert LAG_STEPS >= HORIZON_STEPS, "Set LAG_STEPS >= HORIZON_STEPS to ensure Î” â‰¥ h"

# Choose thresholding mode for triggers
USE_FIXED_THRESHOLDS = True    # True = simple domain cutoffs (fully causal)
                               # False = expanding (past-only) robust thresholds (causal, data-driven)

# Fixed domain thresholds (edit to fit climate/site)
GEN_REL_DROP_THRESH  = -0.15   # >=15% drop between (t-Î”-1) and (t-Î”)
HIGH_TEMP_THRESH     = 40.0    # Â°C
HIGH_HUM_THRESH      = 90.0    # %

# Expanding robust threshold parameters (if USE_FIXED_THRESHOLDS=False)
K_MAD                 = 2.0    # trigger when below median - K * MAD (past-only)
ROLL_RANDOM_RATE      = 0.005  # ~0.5% random background events (exogenous)

OUTPUT_BASENAME       = "FINAL_Synthetic_Maintenance_Logs_LeakageFree_v4.csv"
PROTOCOL_TXT          = "LOG_USAGE_PROTOCOL.txt"
# ------------------------------------------------


# --------------- Load & validate ---------------
if not os.path.exists(MERGED_FILE):
    raise FileNotFoundError(f"Cannot find merged file at: {MERGED_FILE}")

df = pd.read_csv(MERGED_FILE, parse_dates=['Timestamp_Aligned'])

required_cols = ['Timestamp_Aligned', 'SolarGeneration', 'AirTemperature', 'RelativeHumidity']
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Missing required column: {col}")

df = df.sort_values('Timestamp_Aligned').reset_index(drop=True)

# --------------- Build causal lags ---------------
# Past-only features at t come from (t - Î”)
df['SolarGeneration_Lag']  = df['SolarGeneration'].shift(LAG_STEPS)
df['AirTemperature_Lag']   = df['AirTemperature'].shift(LAG_STEPS)
df['RelativeHumidity_Lag'] = df['RelativeHumidity'].shift(LAG_STEPS)

# Relative generation change between (t-Î”-1) -> (t-Î”), fully prior to t
df['GenPrev']          = df['SolarGeneration'].shift(LAG_STEPS + 1)
df['GenRelDrop_Lag']   = (df['SolarGeneration_Lag'] - df['GenPrev']) / df['GenPrev'].clip(lower=1e-6)

# Drop rows without full history (need Î” and Î”+1)
df = df.iloc[LAG_STEPS + 1:].reset_index(drop=True)


# --------------- Causal trigger rules ---------------
if USE_FIXED_THRESHOLDS:
    # Fully causal: fixed a priori rules
    gen_event_mask   = df['GenRelDrop_Lag'] < GEN_REL_DROP_THRESH
    high_temp_mask   = df['AirTemperature_Lag'] > HIGH_TEMP_THRESH
    high_hum_mask    = df['RelativeHumidity_Lag'] > HIGH_HUM_THRESH
else:
    # Causal, data-driven: expanding robust thresholds computed only from past
    # For generation drop: trigger if GenRelDrop_Lag < median_past - K * MAD_past
    exp_med_drop = df['GenRelDrop_Lag'].expanding().median().shift(1)
    exp_mad_drop = (df['GenRelDrop_Lag'] - exp_med_drop).abs().expanding().median().shift(1)
    gen_event_mask = df['GenRelDrop_Lag'] < (exp_med_drop - K_MAD * exp_mad_drop)

    # For temp/humidity: high outliers vs past
    exp_q95_temp = df['AirTemperature_Lag'].expanding().quantile(0.95).shift(1)
    exp_q95_hum  = df['RelativeHumidity_Lag'].expanding().quantile(0.95).shift(1)
    high_temp_mask = df['AirTemperature_Lag']   > exp_q95_temp
    high_hum_mask  = df['RelativeHumidity_Lag'] > exp_q95_hum

gen_event_indices   = set(df.index[gen_event_mask])
high_temp_indices   = set(df.index[high_temp_mask])
high_hum_indices    = set(df.index[high_hum_mask])

# Small exogenous background events (still causal)
np.random.seed(42)
random.seed(42)
rand_n = int(len(df) * ROLL_RANDOM_RATE)
random_indices = set(np.random.choice(df.index, size=rand_n, replace=False)) if rand_n > 0 else set()

# Priority if multiple triggers fire at same t: gen_drop > high_temp > high_hum > random
event_indices = sorted(gen_event_indices | high_temp_indices | high_hum_indices | random_indices)

# --------------- Event synthesis ---------------
maintenance_types = ["Inverter Fault", "Panel Cleaning", "String Fault", "Routine Check", "Sensor Calibration", "Grid Issue"]
components        = ["Inverter", "PV Panel", "String", "Sensor", "Grid Connection"]
operators         = ["Tech John", "Tech Lee", "AutoSensor", "Jane Doe", "Team Alpha"]
actions           = ["resetting", "panel cleaning", "replacing sensor", "reconnecting cable", "firmware update"]

lag_delta = timedelta(minutes=LAG_STEPS * DATA_FREQ_MINUTES)

logs = []
for idx in event_indices:
    row = df.loc[idx]
    t  = row['Timestamp_Aligned']                 # event logged at time t
    t_det = t - lag_delta                         # evidence occurred at (t - Î”)
    t_avail = t                                   # first time the model can see this log

    # resolve priority deterministically
    if idx in gen_event_indices:
        event_type = "Inverter Fault"; severity = "Critical"; comp = "Inverter"
        # describe the change strictly between (t-Î”-1) and (t-Î”)
        drop_pct = 100.0 * float(row['GenRelDrop_Lag'])  # negative value
        desc = (f"Inverter fault suspected: output dropped by {abs(drop_pct):.1f}% "
                f"between (t-{LAG_STEPS+1}) and (t-{LAG_STEPS}). Reset initiated.")
        duration = np.random.randint(60, 180); impact = "Major"
    elif idx in high_temp_indices:
        event_type = "Sensor Calibration"; severity = "Warning"; comp = "Sensor"
        desc = (f"Sensor recalibration scheduled after high temperature observed at "
                f"(t-{LAG_STEPS}) ({row['AirTemperature_Lag']:.2f}Â°C).")
        duration = np.random.randint(20, 60); impact = "Minor"
    elif idx in high_hum_indices:
        event_type = "Panel Cleaning"; severity = "Routine"; comp = "PV Panel"
        desc = (f"Panel cleaning planned after elevated humidity at "
                f"(t-{LAG_STEPS}) ({row['RelativeHumidity_Lag']:.2f}%).")
        duration = np.random.randint(15, 45); impact = "Minor"
    else:
        event_type = random.choice(maintenance_types)
        severity   = random.choice(["Routine", "Minor", "Warning"])
        comp       = random.choice(components)
        op         = random.choice(operators)
        act        = random.choice(actions)
        desc = f"{event_type} performed by {op}; {act} applied."
        duration = np.random.randint(15, 120)
        impact   = random.choice(["None", "Minor", "Reduced by 5%"])

    log = {
        "LogID": idx + 1,
        "Timestamp": t,                      # event time (t)
        "EventDetectedAt": t_det,            # when evidence occurred (â‰¤ t-Î”)
        "AvailableToModelAt": t_avail,       # first time model can use this log
        "HorizonSteps": HORIZON_STEPS,
        "LagSteps": LAG_STEPS,
        "SiteKey": row['SiteKey'] if 'SiteKey' in df.columns else None,
        "MaintenanceType": event_type,
        "Severity": severity,
        "Component": comp,
        "Duration": duration,
        "Operator": random.choice(operators),
        "Description": desc,
        "Resolved": "Yes",
        "ActionTaken": random.choice(actions),
        "SolarImpact": impact
    }
    if 'CampusKey' in df.columns:
        log["CampusKey"] = row['CampusKey']
    logs.append(log)

maintenance_logs_df = pd.DataFrame(logs)

# --------------- Save outputs ---------------
out_dir = os.path.dirname(MERGED_FILE)
output_path = os.path.join(out_dir, OUTPUT_BASENAME)
maintenance_logs_df.to_csv(output_path, index=False)

print(f"\n[SUCCESS] Synthetic logs generated: {output_path}")
print(f"Total logs: {len(maintenance_logs_df)}\n")
print(maintenance_logs_df.head(8))

# --------------- Usage protocol (for your rebuttal & reproducibility) ---------------
usage_protocol = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  USAGE PROTOCOL: PREVENTING TARGET LEAKAGE                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONFIGURATION:
  â€¢ DATA_FREQ_MINUTES = {DATA_FREQ_MINUTES}
  â€¢ LAG_STEPS (Î”)     = {LAG_STEPS}  (Î” Ã— freq = {LAG_STEPS * DATA_FREQ_MINUTES} minutes)
  â€¢ HORIZON_STEPS (h) = {HORIZON_STEPS}  (predict h Ã— freq = {HORIZON_STEPS * DATA_FREQ_MINUTES} minutes ahead)
  â€¢ Enforced: Î” â‰¥ h  âœ…

CAUSAL LOG RULES:
  â€¢ Triggers depend only on values available at (t-Î”) or earlier.
  â€¢ Generation anomaly uses RELATIVE change between (t-Î”-1) and (t-Î”) only.
  â€¢ No rule inspects SolarGeneration at time t.

TIMING GUARANTEES:
  â€¢ Each log row includes:
      - EventDetectedAt    = t - Î”  (when the evidence occurred)
      - AvailableToModelAt = t      (first time the model can use this log)
  â€¢ When building features at time t, only aggregate logs with AvailableToModelAt â‰¤ t.

MODEL PIPELINE (example):
  1) Merge logs onto your aligned time series by time window, e.g. counts/recency in [t-W, t]
     using AvailableToModelAt for window filtering.
  2) Create the forecasting target h steps ahead:
       df['Target'] = df['SolarGeneration'].shift(-{HORIZON_STEPS})
     and drop the last {HORIZON_STEPS} rows (no target there).
  3) Train: features at time t â†’ predict Target at time t+h.

EVALUATION:
  â€¢ Use rolling-origin (expanding window) splits; fit scalers/embedders on TRAIN ONLY.
  â€¢ Ablations: numeric-only vs numeric+logs; permutation of logs to confirm utility.

THRESHOLDS:
  â€¢ {'Fixed domain thresholds (GEN_REL_DROP_THRESH, HIGH_TEMP_THRESH, HIGH_HUM_THRESH).' if USE_FIXED_THRESHOLDS else f'Expanding robust thresholds with K_MAD={K_MAD} (no look-ahead).'}
"""

protocol_path = os.path.join(out_dir, PROTOCOL_TXT)
with open(protocol_path, "w") as f:
    f.write(usage_protocol)

print(usage_protocol)
print(f"ğŸ“„ Usage protocol saved: {protocol_path}")
