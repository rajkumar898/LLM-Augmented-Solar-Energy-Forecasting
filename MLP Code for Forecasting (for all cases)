##################################
# CASE 1: SOLAR + WEATHER DATA
##################################

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# Load & preprocess dataset
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# Create lag feature from SolarGeneration
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

# Select embedding columns
embedding_cols = [col for col in df.columns if col.startswith("text_emb_mean_")]

# Combine lag feature and embeddings for features
features = ["lag1"] + embedding_cols

X = df[features].values
y = df["SolarGeneration"].values

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y, dtype=np.float64)
fold_metrics = []
train_times = []

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    mlp = MLPRegressor(
        hidden_layer_sizes=(256, 128, 64),
        activation='relu',
        solver='adam',
        alpha=1e-3,
        batch_size=512,
        learning_rate='adaptive',
        learning_rate_init=1e-4,
        max_iter=500,
        tol=1e-4,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=15,
        random_state=42,
        verbose=False
    )

    start_time = time.time()
    mlp.fit(X_train, y_train)
    train_times.append(time.time() - start_time)

    y_pred = mlp.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values

    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)

    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

# Plot results

plt.figure(figsize=(15,7))
plt.plot(y, label='Actual Solar Generation', color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label='Predicted Solar Generation', color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel('Time Steps')
plt.ylabel('Solar Generation')
plt.title('MLP Generation Prediction (Case 2: Solar + Text Embeddings)')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title('MLP Prediction Scatter (Case 2: Solar + Text Embeddings)')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.tight_layout()
plt.show()

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7,6))
scatter = plt.scatter(X_embedded[:,0], X_embedded[:,1], c=y_pred_full_smoothed, cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label='Predicted Solar Generation')
plt.title('MLP t-SNE of MLP Predictions (Case 2: Solar + Text Embeddings)')
plt.xlabel('Component 1')
plt.ylabel('Component 2')
plt.grid(True)
plt.tight_layout()
plt.show()

errors = y - y_pred_full_smoothed
plt.figure(figsize=(8,4))
sns.histplot(errors, kde=True, bins=70, color='orange')
plt.xlabel('Prediction Error (Actual - Predicted)')
plt.title('MLP Distribution of MLP Prediction Errors (Case 2: Solar + Text Embeddings)')
plt.grid(True)
plt.tight_layout()
plt.show()

# Boxplot error by hour if 'hour' exists
if 'hour' in df.columns:
    df_plot = pd.DataFrame({
        'error': np.abs(y - y_pred_full_smoothed),
        'hour': df['hour'].values
    })
    plt.figure(figsize=(12,4))
    sns.boxplot(x='hour', y='error', data=df_plot)
    plt.xlabel('Hour of Day')
    plt.ylabel('Absolute Error')
    plt.title('MLP Prediction Error by Hour (Case 2: Solar + Text Embeddings)')
    plt.tight_layout()
    plt.show()

plt.figure(figsize=(6,6))
stats.probplot(errors, dist='norm', plot=plt)
plt.title('MLP QQ Plot of MLP Residuals (Case 2: Solar + Text Embeddings)')
plt.tight_layout()
plt.show()

# Metrics summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)
print('\nFold-wise Metrics:')
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f'Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}')
print(f'\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}')

# Computational complexity
total_training_time = sum(train_times)
param_count = sum(coef.size for coef in mlp.coefs_) + sum(intercept.size for intercept in mlp.intercepts_)

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat

inference_time_ms = measure_inference_time(mlp, X_scaled)
print(f'\nTotal Training Time (s): {total_training_time:.2f}')
print(f'Parameter Count: {param_count}')
print(f'Average Inference Time per Sample (ms): {inference_time_ms:.3f}')

print('FLOPs for sklearn MLP not available; parameter count and timings reported instead.')


########################################
# CASE 2: SOLAR + TEXT EMBEDDING DATA
########################################

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# Load & preprocess dataset
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# Create lag feature from SolarGeneration
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

# Select embedding columns
embedding_cols = [col for col in df.columns if col.startswith("text_emb_mean_")]

# Combine lag feature and embeddings for features
features = ["lag1"] + embedding_cols

X = df[features].values
y = df["SolarGeneration"].values

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y, dtype=np.float64)
fold_metrics = []
train_times = []

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    mlp = MLPRegressor(
        hidden_layer_sizes=(256, 128, 64),
        activation='relu',
        solver='adam',
        alpha=1e-3,
        batch_size=512,
        learning_rate='adaptive',
        learning_rate_init=1e-4,
        max_iter=500,
        tol=1e-4,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=15,
        random_state=42,
        verbose=False
    )

    start_time = time.time()
    mlp.fit(X_train, y_train)
    train_times.append(time.time() - start_time)

    y_pred = mlp.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values

    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)

    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

# Plot results

plt.figure(figsize=(15,7))
plt.plot(y, label='Actual Solar Generation', color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label='Predicted Solar Generation', color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel('Time Steps')
plt.ylabel('Solar Generation')
plt.title('MLP Generation Prediction (Case 2: Solar + Text Embeddings)')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title('MLP Prediction Scatter (Case 2: Solar + Text Embeddings)')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.tight_layout()
plt.show()

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7,6))
scatter = plt.scatter(X_embedded[:,0], X_embedded[:,1], c=y_pred_full_smoothed, cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label='Predicted Solar Generation')
plt.title('MLP t-SNE of MLP Predictions (Case 2: Solar + Text Embeddings)')
plt.xlabel('Component 1')
plt.ylabel('Component 2')
plt.grid(True)
plt.tight_layout()
plt.show()

errors = y - y_pred_full_smoothed
plt.figure(figsize=(8,4))
sns.histplot(errors, kde=True, bins=70, color='orange')
plt.xlabel('Prediction Error (Actual - Predicted)')
plt.title('MLP Distribution of MLP Prediction Errors (Case 2: Solar + Text Embeddings)')
plt.grid(True)
plt.tight_layout()
plt.show()

# Boxplot error by hour if 'hour' exists
if 'hour' in df.columns:
    df_plot = pd.DataFrame({
        'error': np.abs(y - y_pred_full_smoothed),
        'hour': df['hour'].values
    })
    plt.figure(figsize=(12,4))
    sns.boxplot(x='hour', y='error', data=df_plot)
    plt.xlabel('Hour of Day')
    plt.ylabel('Absolute Error')
    plt.title('MLP Prediction Error by Hour (Case 2: Solar + Text Embeddings)')
    plt.tight_layout()
    plt.show()

plt.figure(figsize=(6,6))
stats.probplot(errors, dist='norm', plot=plt)
plt.title('MLP QQ Plot of MLP Residuals (Case 2: Solar + Text Embeddings)')
plt.tight_layout()
plt.show()

# Metrics summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)
print('\nFold-wise Metrics:')
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f'Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}')
print(f'\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}')

# Computational complexity
total_training_time = sum(train_times)
param_count = sum(coef.size for coef in mlp.coefs_) + sum(intercept.size for intercept in mlp.intercepts_)

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat

inference_time_ms = measure_inference_time(mlp, X_scaled)
print(f'\nTotal Training Time (s): {total_training_time:.2f}')
print(f'Parameter Count: {param_count}')
print(f'Average Inference Time per Sample (ms): {inference_time_ms:.3f}')

print('FLOPs for sklearn MLP not available; parameter count and timings reported instead.')


########################################
# CASE 3: WEATHER + TEXT EMBEDDING DATA
########################################

import pandas as pd
import numpy as np
import time
import os
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# 1. Load & Clean, Subset first 25k rows
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# 2. Feature Engineering (Weather + Logs + Temporal)
df["hour"] = df["Timestamp_Aligned"].dt.hour
df["dayofyear"] = df["Timestamp_Aligned"].dt.dayofyear
df["hour_sin"] = np.sin(2*np.pi*df["hour"] / 24)
df["hour_cos"] = np.cos(2*np.pi*df["hour"] / 24)
df["doy_sin"] = np.sin(2*np.pi*df["dayofyear"] / 365)
df["doy_cos"] = np.cos(2*np.pi*df["dayofyear"] / 365)
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

weather_cols = ["AirTemperature", "RelativeHumidity", "WindSpeed",
                "WindDirection", "ApparentTemperature", "DewPointTemperature"]
embedding_cols = [c for c in df.columns if c.startswith("log_emb_")]
features = weather_cols + embedding_cols + ["hour_sin", "hour_cos", "doy_sin", "doy_cos", "lag1"]

X = df[features].values
y = df["SolarGeneration"].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    mlp = MLPRegressor(
        hidden_layer_sizes=(256, 128, 64),
        activation='relu',
        solver='adam',
        alpha=1e-3,
        batch_size=512,
        learning_rate='adaptive',
        learning_rate_init=1e-4,
        max_iter=500,
        tol=1e-4,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=15,
        random_state=42,
        verbose=False
    )

    start_time = time.time()
    mlp.fit(X_train, y_train)
    end_time = time.time()
    train_times.append(end_time - start_time)

    y_pred = mlp.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)

    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

# Smooth full predictions for plotting
y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

# Generation plot
plt.figure(figsize=(15,7))
plt.plot(y, label='Actual Solar Generation', color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label='Predicted Solar Generation', color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel('Time Steps'); plt.ylabel('Solar Generation')
plt.title('MLP Generation Prediction (Case 3: Weather + Text Embeddings)')
plt.legend(); plt.grid()
plt.tight_layout()
plt.show()

# Scatter plot
plt.figure(figsize=(7,7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], "r--")
plt.title('MLP Prediction Scatter (Case 3: Weather + Text Embeddings)')
plt.xlabel('Actual'); plt.ylabel('Predicted')
plt.tight_layout()
plt.show()

# t-SNE plot
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7,6))
scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_pred_full_smoothed, cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label='Predicted Solar Generation')
plt.title('MLP t-SNE of Predictions (Case 3: Weather + Text Embeddings)')
plt.xlabel('Component 1'); plt.ylabel('Component 2')
plt.grid(True)
plt.tight_layout()
plt.show()

# Error distribution
errors = y - y_pred_full_smoothed
plt.figure(figsize=(8,4))
sns.histplot(errors, kde=True, bins=70, color='orange')
plt.xlabel('Prediction Error (Actual - Predicted)')
plt.title('MLP Distribution of Prediction Errors (Case 3: Weather + Text Embeddings)')
plt.grid(True)
plt.tight_layout()
plt.show()

# Boxplot of error by hour
df_plot = pd.DataFrame({
    'error': np.abs(y - y_pred_full_smoothed),
    'hour': df['hour'].values
})
plt.figure(figsize=(12,4))
sns.boxplot(x='hour', y='error', data=df_plot)
plt.xlabel('Hour of Day'); plt.ylabel('Absolute Error')
plt.title('MLP Prediction Error by Hour (Case 3: Weather + Text Embeddings)')
plt.tight_layout()
plt.show()

# QQ plot
fig = plt.figure(figsize=(6,6))
stats.probplot(errors, dist='norm', plot=plt)
plt.title('MLP QQ Plot of Residuals (Case 3: Weather + Text Embeddings)')
plt.tight_layout()
plt.show()

# Print metrics
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)
print('\nFold-wise Metrics:')
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f'Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}')
print(f'\nAverage over folds: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}')

# Computational complexity: parameters, training time, inference time
total_train_time = sum(train_times)
param_count = mlp.coefs_[0].size + mlp.coefs_[1].size + mlp.coefs_[2].size + mlp.intercepts_[0].size + mlp.intercepts_[1].size + mlp.intercepts_[2].size

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat  # ms

inference_time_ms = measure_inference_time(mlp, X_scaled)

print(f'\nTotal Training Time (s): {total_train_time:.2f}')
print(f'Count of Parameters: {param_count}')
print(f'Average Inference Time per Sample (ms): {inference_time_ms:.3f}')

print('FLOPs calculation not available for sklearn MLP, approximate parameter count and timing reported.')


########################################
# CASE 4: TEXT EMBEDDING DATA ONLY
########################################

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# Load & pre-process
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# Correct embedding column prefix for maintenance log embeddings
embedding_cols = [c for c in df.columns if c.startswith("text_emb_mean_")]

if len(embedding_cols) == 0:
    raise ValueError("No 'text_emb_mean_' embedding columns found. Please check dataset columns.")

X = df[embedding_cols].values
y = df["SolarGeneration"].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    mlp = MLPRegressor(
        hidden_layer_sizes=(256, 128, 64),
        activation='relu',
        solver='adam',
        alpha=1e-3,
        batch_size=512,
        learning_rate='adaptive',
        learning_rate_init=1e-4,
        max_iter=500,
        tol=1e-4,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=15,
        random_state=42,
        verbose=False
    )

    start_time = time.time()
    mlp.fit(X_train, y_train)
    train_times.append(time.time() - start_time)

    y_pred = mlp.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)

    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

# Generation plot
plt.figure(figsize=(15,7))
plt.plot(y, label='Actual Solar Generation', color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label='Predicted Solar Generation', color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel('Time Steps')
plt.ylabel('Solar Generation')
plt.title('MLP Generation Prediction (Case 4: Maintenance Log Embeddings Only)')
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# Scatter plot
plt.figure(figsize=(7,7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title('MLP Prediction Scatter (Case 4: Maintenance Log Embeddings Only)')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.tight_layout()
plt.show()

# t-SNE plot
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7,6))
scatter = plt.scatter(X_embedded[:,0], X_embedded[:,1], c=y_pred_full_smoothed, cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label='Predicted Solar Generation')
plt.title('MLP t-SNE of Predictions (Case 4: Maintenance Log Embeddings Only)')
plt.xlabel('Component 1')
plt.ylabel('Component 2')
plt.grid(True)
plt.tight_layout()
plt.show()

# Error histogram
errors = y - y_pred_full_smoothed
plt.figure(figsize=(8,4))
sns.histplot(errors, kde=True, bins=70, color='orange')
plt.xlabel('Prediction Error (Actual - Predicted)')
plt.title('MLP Distribution of Prediction Errors (Case 4: Maintenance Log Embeddings Only)')
plt.grid(True)
plt.tight_layout()
plt.show()

# Boxplot of error by hour (not present for log embeddings only, but code here if needed)
if 'hour' in df.columns:
    df_plot = pd.DataFrame({
        'error': np.abs(y - y_pred_full_smoothed),
        'hour': df['hour'].values
    })
    plt.figure(figsize=(12,4))
    sns.boxplot(x='hour', y='error', data=df_plot)
    plt.xlabel('Hour of Day')
    plt.ylabel('Absolute Error')
    plt.title('MLP Prediction Error by Hour (Case 4: Maintenance Log Embeddings Only)')
    plt.tight_layout()
    plt.show()

# QQ plot
fig = plt.figure(figsize=(6,6))
stats.probplot(errors, dist='norm', plot=plt)
plt.title('MLP QQ Plot of Residuals (Case 4: Maintenance Log Embeddings Only)')
plt.tight_layout()
plt.show()

# Fold-wise metrics and average
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)
print('\nFold-wise Metrics:')
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f'Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}')
print(f'\nAverage over folds: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}')

# Computational complexity
total_train_time = sum(train_times)
param_count = sum(coef.size for coef in mlp.coefs_) + sum(intercept.size for intercept in mlp.intercepts_)

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat

inference_time_ms = measure_inference_time(mlp, X_scaled)

print(f'\nTotal Training Time (s): {total_train_time:.2f}')
print(f'Parameter Count: {param_count}')
print(f'Average Inference Time per Sample (ms): {inference_time_ms:.3f}')

print('FLOPs for sklearn MLP not available; parameter count and timings reported instead.')


###################################################################
# CASE 5: MULTIMODAL DATA (SOLAR + WEATHER + TEXT EMBEDDING)
###################################################################

import pandas as pd
import numpy as np
import time
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# Load & preprocess
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# Feature engineering for temporal data
df["hour"] = df["Timestamp_Aligned"].dt.hour
df["dayofyear"] = df["Timestamp_Aligned"].dt.dayofyear
df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
df["doy_sin"] = np.sin(2 * np.pi * df["dayofyear"] / 365)
df["doy_cos"] = np.cos(2 * np.pi * df["dayofyear"] / 365)
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

# Define features list
weather_cols = [
    "AirTemperature", "RelativeHumidity", "WindSpeed",
    "WindDirection", "ApparentTemperature", "DewPointTemperature"
]
embedding_cols = [col for col in df.columns if col.startswith("text_emb_mean_")]
temporal_cols = ["hour_sin", "hour_cos", "doy_sin", "doy_cos", "lag1"]

features = weather_cols + embedding_cols + temporal_cols

X = df[features].values
y = df["SolarGeneration"].values

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Setup CV
kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    mlp = MLPRegressor(
        hidden_layer_sizes=(256, 128, 64),
        activation="relu",
        solver="adam",
        alpha=1e-3,
        batch_size=512,
        learning_rate="adaptive",
        learning_rate_init=1e-4,
        max_iter=500,
        tol=1e-4,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=15,
        random_state=42,
        verbose=False,
    )

    start_time = time.time()
    mlp.fit(X_train, y_train)
    train_times.append(time.time() - start_time)

    y_pred = mlp.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)

    print(f"Fold {fold} -> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

# Plot generation
plt.figure(figsize=(15, 7))
plt.plot(y, label="Actual Solar Generation", color="tab:blue", alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label="Predicted Solar Generation", color="tab:orange", alpha=0.8, linewidth=1)
plt.xlabel("Time Steps")
plt.ylabel("Solar Generation")
plt.title("MLP Generation Prediction (Case 5: Multimodal)")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# Scatter plot
plt.figure(figsize=(7, 7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], "r--")
plt.title("MLP Prediction Scatter (Case 5: Multimodal)")
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.tight_layout()
plt.show()

# t-SNE plot
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7, 6))
scatter = plt.scatter(
    X_embedded[:, 0], X_embedded[:, 1], c=y_pred_full_smoothed, cmap="viridis", alpha=0.7
)
plt.colorbar(scatter, label="Predicted Solar Generation")
plt.title("MLP t-SNE of Predictions (Case 5: Multimodal)")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.grid(True)
plt.tight_layout()
plt.show()

# Error histogram
errors = y - y_pred_full_smoothed
plt.figure(figsize=(8, 4))
sns.histplot(errors, kde=True, bins=70, color="orange")
plt.xlabel("Prediction Error (Actual - Predicted)")
plt.title("MLP Distribution of Prediction Errors (Case 5: Multimodal)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Boxplot by hour (if hour feature present)
if "hour" in df.columns:
    df_plot = pd.DataFrame({"error": np.abs(y - y_pred_full_smoothed), "hour": df["hour"].values})
    plt.figure(figsize=(12, 4))
    sns.boxplot(x="hour", y="error", data=df_plot)
    plt.xlabel("Hour of Day")
    plt.ylabel("Absolute Error")
    plt.title("MLP Prediction Error by Hour (Case 5: Multimodal)")
    plt.tight_layout()
    plt.show()

# QQ plot
plt.figure(figsize=(6, 6))
stats.probplot(errors, dist="norm", plot=plt)
plt.title("MLP QQ Plot of Residuals (Case 5: Multimodal)")
plt.tight_layout()
plt.show()

# Metrics summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)
print("\nFold-wise Metrics:")
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f"Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")
print(f"\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}")

# Computational complexity
total_training_time = sum(train_times)
param_count = sum(coef.size for coef in mlp.coefs_) + sum(intercept.size for intercept in mlp.intercepts_)

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat

inference_time_ms = measure_inference_time(mlp, X_scaled)

print(f"\nTotal Training Time (s): {total_training_time:.2f}")
print(f"Parameter Count: {param_count}")
print(f"Average Inference Time per Sample (ms): {inference_time_ms:.3f}")

print("Note: FLOPs not available for sklearn MLP; parameter count and timings reported.")
