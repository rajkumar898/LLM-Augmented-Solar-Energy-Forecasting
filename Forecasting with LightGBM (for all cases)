##################################
# CASE 1: SOLAR + WEATHER DATA
##################################

import pandas as pd
import numpy as np
import time
import os
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# 1. Load & preprocess dataset (first 25k rows)
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# 2. Temporal feature engineering
df["hour"] = df["Timestamp_Aligned"].dt.hour
df["dayofyear"] = df["Timestamp_Aligned"].dt.dayofyear
df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
df["doy_sin"] = np.sin(2 * np.pi * df["dayofyear"] / 365)
df["doy_cos"] = np.cos(2 * np.pi * df["dayofyear"] / 365)
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

# 3. Select weather features only
weather_cols = [
    "AirTemperature", "RelativeHumidity",
    "WindSpeed", "WindDirection",
    "ApparentTemperature", "DewPointTemperature"
]
temporal_cols = ["hour_sin", "hour_cos", "doy_sin", "doy_cos", "lag1"]

features = weather_cols + temporal_cols

X = df[features].values
y = df["SolarGeneration"].values

# 4. Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5. Cross-validation & model training
kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []
model_obj = None
start_total_train = time.time()

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    model = lgb.LGBMRegressor(
        objective="regression",
        boosting_type="gbdt",
        n_estimators=200,
        learning_rate=0.05,
        num_leaves=31,
        max_depth=7,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        verbose=-1
    )
    fold_start = time.time()
    model.fit(X_train, y_train)
    fold_end = time.time()
    train_times.append(fold_end - fold_start)

    y_pred = model.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)
    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

    if fold == 5:
        model_obj = model

total_train_time = sum(train_times)

# 6. Plots

y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

plt.figure(figsize=(15,7))
plt.plot(y, label="Actual Solar Generation", color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label="Predicted Solar Generation", color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel("Time Steps")
plt.ylabel("Solar Generation")
plt.title("LightGBM Generation Prediction (Case 5: Multimodal)")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("LightGBM Prediction Scatter (Case 1: Solar + Weather)")
plt.tight_layout()
plt.show()

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7,6))
scatter = plt.scatter(X_embedded[:,0], X_embedded[:,1], c=y_pred_full_smoothed, cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label="Predicted Solar Generation")
plt.title("LightGBM Predictions t-SNE (Case 1: Solar + Weather)")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.grid(True)
plt.tight_layout()
plt.show()

errors = y - y_pred_full_smoothed
plt.figure(figsize=(8,4))
sns.histplot(errors, kde=True, bins=70, color='orange')
plt.xlabel("Prediction Error (Actual - Predicted)")
plt.title("LightGBM Prediction Error Distribution (Case 1: Solar + Weather)")
plt.grid(True)
plt.tight_layout()
plt.show()

df_plot = pd.DataFrame({'error': np.abs(y - y_pred_full_smoothed), 'hour': df["hour"].values})
plt.figure(figsize=(12,4))
sns.boxplot(x='hour', y='error', data=df_plot)
plt.xlabel('Hour of Day')
plt.ylabel('Absolute Error')
plt.title('LightGBM Prediction Error by Hour (Case 1: Solar + Weather)')
plt.tight_layout()
plt.show()

fig = plt.figure(figsize=(6,6))
stats.probplot(errors, dist='norm', plot=plt)
plt.title("LightGBM QQ Plot of Residuals (Case 1: Solar + Weather)")
plt.tight_layout()
plt.show()

# 7. Fold metrics summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)
print("\nFold-wise Metrics:")
for i, (rmse, mae, r2) in enumerate(fold_metrics,1):
    print(f"Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

print(f"\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}")

# 8. Computational complexity
model_obj.booster_.save_model('lgb_model_case1.txt')
n_trees = model_obj.n_estimators
n_leaves = model_obj.num_leaves
params = n_trees * n_leaves
model_size_kb = os.path.getsize('lgb_model_case1.txt') / 1024

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat

inference_time_ms = measure_inference_time(model_obj, X_scaled)

print(f"\nTotal Training Time (s): {total_train_time:.2f}")
print(f"Approximate Number of Parameters: {params}")
print(f"Model Size on Disk: {model_size_kb:.2f} KB")
print(f"Average Inference Time per Sample (ms): {inference_time_ms:.3f}")

print("Note: FLOPs not standardized for LightGBM; #params × timings reported as proxy.")

########################################
# CASE 2: SOLAR + TEXT EMBEDDING DATA
########################################

import pandas as pd
import numpy as np
import time
import os
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# 1. Load & preprocess dataset
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# 2. Add lag feature from solar generation (typical temporal feature)
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

# 3. Select embedding columns with correct prefix
embedding_cols = [col for col in df.columns if col.startswith("text_emb_mean_")]

# Features: lagged solar generation + embeddings
features = ["lag1"] + embedding_cols

X = df[features].values
y = df["SolarGeneration"].values

# 4. Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5. Cross-validation setup
kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []
model_obj = None

start_total_train = time.time()

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    model = lgb.LGBMRegressor(
        objective="regression",
        boosting_type="gbdt",
        n_estimators=200,
        learning_rate=0.05,
        num_leaves=31,
        max_depth=7,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        verbose=-1
    )

    fold_start = time.time()
    model.fit(X_train, y_train)
    fold_end = time.time()
    train_times.append(fold_end - fold_start)

    y_pred = model.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)
    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

    if fold == 5:
        model_obj = model

total_train_time = sum(train_times)

# 6. Plots
y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

plt.figure(figsize=(15, 7))
plt.plot(y, label="Actual Solar Generation", color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label="Predicted Solar Generation", color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel("Time Steps")
plt.ylabel("Solar Generation")
plt.title("LightGBM Generation Prediction (Case 2: Solar + Text Embeddings)")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

plt.figure(figsize=(7, 7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("LightGBM Prediction Scatter (Case 2: Solar + Text Embeddings)")
plt.tight_layout()
plt.show()

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7, 6))
scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_pred_full_smoothed, cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label="Predicted Solar Generation")
plt.title("LightGBM t-SNE of Predictions (Case 2: Solar + Text Embeddings)")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.grid(True)
plt.tight_layout()
plt.show()

errors = y - y_pred_full_smoothed
plt.figure(figsize=(8, 4))
sns.histplot(errors, kde=True, bins=70, color='orange')
plt.xlabel("Prediction Error (Actual - Predicted)")
plt.title("LightGBM Error Distribution (Case 2: Solar + Text Embeddings)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Boxplot error by hour if exists
if "hour" in df.columns:
    df_plot = pd.DataFrame({
        "error": np.abs(y - y_pred_full_smoothed),
        "hour": df["hour"].values
    })
    plt.figure(figsize=(12, 4))
    sns.boxplot(x="hour", y="error", data=df_plot)
    plt.xlabel("Hour of Day")
    plt.ylabel("Absolute Error")
    plt.title("LightGBM Prediction Error by Hour (Case 2: Solar + Text Embeddings)")
    plt.tight_layout()
    plt.show()

fig = plt.figure(figsize=(6, 6))
stats.probplot(errors, dist="norm", plot=plt)
plt.title("LightGBM QQ Plot of Residuals (Case 2: Solar + Text Embeddings)")
plt.tight_layout()
plt.show()

# 7. Fold metrics summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)
print("\nFold-wise Metrics:")
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f"Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

print(f"\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}")

# 8. Computational complexity info
model_obj.booster_.save_model('lgb_model_case2.txt')
n_trees = model_obj.n_estimators
n_leaves = model_obj.num_leaves
params = n_trees * n_leaves
model_size_kb = os.path.getsize('lgb_model_case2.txt') / 1024

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat

inference_time_ms = measure_inference_time(model_obj, X_scaled)

print(f"\nTotal Training Time (s): {total_train_time:.2f}")
print(f"Approximate Number of Parameters: {params}")
print(f"Model Size on Disk: {model_size_kb:.2f} KB")
print(f"Average Inference Time per Sample (ms): {inference_time_ms:.3f}")

print("Note: FLOPs not standardized; proxy metrics reported.")

########################################
# CASE 3: WEATHER + TEXT EMBEDDING DATA
########################################

import pandas as pd
import numpy as np
import time
import os
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings

warnings.filterwarnings("ignore")

# 1. Load & Clean, Subset first 25k rows
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# 2. Feature Engineering: Weather + Log Embeddings + Temporal
df["hour"] = df["Timestamp_Aligned"].dt.hour
df["dayofyear"] = df["Timestamp_Aligned"].dt.dayofyear
df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
df["doy_sin"] = np.sin(2 * np.pi * df["dayofyear"] / 365)
df["doy_cos"] = np.cos(2 * np.pi * df["dayofyear"] / 365)
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

weather_cols = ["AirTemperature", "RelativeHumidity", "WindSpeed",
                "WindDirection", "ApparentTemperature", "DewPointTemperature"]
embedding_cols = [c for c in df.columns if c.startswith("text_emb_mean_")]
temporal_cols = ["hour_sin", "hour_cos", "doy_sin", "doy_cos", "lag1"]

features = weather_cols + embedding_cols + temporal_cols

X = df[features].values
y = df["SolarGeneration"].values

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Cross-validation and training
kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []
model_obj = None

start_total_train = time.time()

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    model = lgb.LGBMRegressor(
        objective="regression",
        boosting_type="gbdt",
        n_estimators=200,
        learning_rate=0.05,
        num_leaves=31,
        max_depth=7,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        verbose=-1
    )

    fold_start = time.time()
    model.fit(X_train, y_train)
    fold_end = time.time()
    train_times.append(fold_end - fold_start)

    y_pred = model.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)

    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

    if fold == 5:
        model_obj = model

total_train_time = sum(train_times)

# 4. Supporting plots
y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

plt.figure(figsize=(15, 7))
plt.plot(y, label="Actual Solar Generation", color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label="Predicted Solar Generation", color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel("Time Steps")
plt.ylabel("Solar Generation")
plt.title("LightGBM Generation Prediction (Case 3: Weather + Text Embeddings)")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

plt.figure(figsize=(7, 7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title("LightGBM Prediction Scatter (Case 3: Weather + Text Embeddings)")
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.tight_layout()
plt.show()

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7, 6))
scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_pred_full_smoothed,
                      cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label="Predicted Solar Generation")
plt.title("LightGBM t-SNE of Predictions (Case 3: Weather + Text Embeddings)")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.grid(True)
plt.tight_layout()
plt.show()

errors = y - y_pred_full_smoothed
plt.figure(figsize=(8, 4))
sns.histplot(errors, kde=True, bins=70, color="orange")
plt.xlabel("Prediction Error (Actual - Predicted)")
plt.title("LightGBM Prediction Errors Distribution (Case 3: Weather + Text Embeddings)")
plt.grid(True)
plt.tight_layout()
plt.show()

if "hour" in df.columns:
    df_plot = pd.DataFrame({
        "error": np.abs(y - y_pred_full_smoothed),
        "hour": df["hour"].values
    })
    plt.figure(figsize=(12, 4))
    sns.boxplot(x="hour", y="error", data=df_plot)
    plt.xlabel("Hour of Day")
    plt.ylabel("Absolute Error")
    plt.title("LightGBM Prediction Error by Hour (Case 3: Weather + Text Embeddings)")
    plt.tight_layout()
    plt.show()

fig = plt.figure(figsize=(6, 6))
stats.probplot(errors, dist="norm", plot=plt)
plt.title("LightGBM QQ Plot of Residuals (Case 3: Weather + Text Embeddings)")
plt.tight_layout()
plt.show()

# 5. Fold-wise metric summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)

print("\nFold-wise Metrics:")
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f"Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

print(f"\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}")

# 6. Computational complexity
model_obj.booster_.save_model('lgb_model_case3.txt')
n_trees = model_obj.n_estimators
n_leaves = model_obj.num_leaves
params = n_trees * n_leaves
model_size_kb = os.path.getsize('lgb_model_case3.txt') / 1024


def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat


inference_time_ms = measure_inference_time(model_obj, X_scaled)

print(f"\nTotal Training Time (s): {total_train_time:.2f}")
print(f"Approximate Number of Parameters: {params}")
print(f"Model Size on Disk: {model_size_kb:.2f} KB")
print(f"Average Inference Time per Sample (ms): {inference_time_ms:.3f}")

print("Note: FLOPs not standardized for LightGBM; #params × timings reported as proxy.")

########################################
# CASE 4: TEXT EMBEDDING DATA ONLY
########################################

import pandas as pd
import numpy as np
import time
import os
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings

warnings.filterwarnings("ignore")

# Load and subset first 25k rows
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# Select maintenance log embedding columns with prefix 'text_emb_mean_'
embedding_cols = [col for col in df.columns if col.startswith("text_emb_mean_")]

X = df[embedding_cols].values
y = df["SolarGeneration"].values

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []
model_obj = None

start_total_train = time.time()

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    model = lgb.LGBMRegressor(
        objective="regression",
        boosting_type="gbdt",
        n_estimators=200,
        learning_rate=0.05,
        num_leaves=31,
        max_depth=7,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        verbose=-1
    )

    fold_start = time.time()
    model.fit(X_train, y_train)
    fold_end = time.time()
    train_times.append(fold_end - fold_start)

    y_pred = model.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values

    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)

    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")

    fold_metrics.append((rmse, mae, r2))

    if fold == 5:
        model_obj = model  # Save model for complexity reporting

total_train_time = sum(train_times)

y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

# Generation Plot
plt.figure(figsize=(15, 7))
plt.plot(y, label="Actual Solar Generation", color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label="Predicted Solar Generation", color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel("Time Steps")
plt.ylabel("Solar Generation")
plt.title("LightGBM Generation Prediction (Case 4: Maintenance Log Embeddings Only)")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

# Scatter Plot
plt.figure(figsize=(7, 7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], "r--")
plt.title("LightGBM Prediction Scatter (Case 4: Maintenance Log Embeddings Only)")
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.tight_layout()
plt.show()

# t-SNE Plot
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7, 6))
scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_pred_full_smoothed, cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label="Predicted Solar Generation")
plt.title("LightGBM t-SNE of Predictions (Case 4: Maintenance Log Embeddings Only)")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.grid(True)
plt.tight_layout()
plt.show()

# Error Histogram
errors = y - y_pred_full_smoothed
plt.figure(figsize=(8, 4))
sns.histplot(errors, kde=True, bins=70, color="orange")
plt.xlabel("Prediction Error (Actual - Predicted)")
plt.title("LightGBM Distribution of Prediction Errors (Case 4: Maintenance Log Embeddings Only)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Boxplot Error by hour (only if hourly data exists)
if "hour" in df.columns:
    df_plot = pd.DataFrame({
        "error": np.abs(y - y_pred_full_smoothed),
        "hour": df["hour"].values
    })
    plt.figure(figsize=(12, 4))
    sns.boxplot(x="hour", y="error", data=df_plot)
    plt.xlabel("Hour of Day")
    plt.ylabel("Absolute Error")
    plt.title("LightGBM Prediction Error by Hour (Case 4: Maintenance Log Embeddings Only)")
    plt.tight_layout()
    plt.show()

# QQ Plot
fig = plt.figure(figsize=(6, 6))
stats.probplot(errors, dist="norm", plot=plt)
plt.title("LightGBM QQ Plot of Residuals (Case 4: Maintenance Log Embeddings Only)")
plt.tight_layout()
plt.show()

# Fold metrics summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)

print("\nFold-wise Metrics:")
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f"Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

print(f"\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}")

# Computational complexity measures
model_obj.booster_.save_model("lgb_model_case4.txt")
n_trees = model_obj.n_estimators
n_leaves = model_obj.num_leaves
params = n_trees * n_leaves
model_size_kb = os.path.getsize("lgb_model_case4.txt") / 1024


def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat


inference_time_ms = measure_inference_time(model_obj, X_scaled)

print(f"\nTotal Training Time (s): {total_train_time:.2f}")
print(f"Approximate Number of Parameters: {params}")
print(f"Model Size on Disk: {model_size_kb:.2f} KB")
print(f"Average Inference Time per Sample (ms): {inference_time_ms:.3f}")

print("Note: FLOPs not standardized for LightGBM; #params × timings reported as proxy.")

###################################################################
# CASE 5: MULTIMODAL DATA (SOLAR + WEATHER + TEXT EMBEDDING)
###################################################################

import pandas as pd
import numpy as np
import time
import os
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.manifold import TSNE
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import warnings
warnings.filterwarnings("ignore")

# 1. Load & Clean, Subset to First 25,000 steps
df = pd.read_csv(
    r"/home/raj/RE Revision/Multimodal_Causal_W96_H4.csv",
    parse_dates=["Timestamp_Aligned"]
)
df["SolarGeneration"] = df["SolarGeneration"].fillna(0)
df = df.dropna()
df = df.iloc[:25000]

# 2. Feature Engineering (add temporal features)
df["hour"] = df["Timestamp_Aligned"].dt.hour
df["dayofyear"] = df["Timestamp_Aligned"].dt.dayofyear
df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
df["doy_sin"] = np.sin(2 * np.pi * df["dayofyear"] / 365)
df["doy_cos"] = np.cos(2 * np.pi * df["dayofyear"] / 365)
df["lag1"] = df["SolarGeneration"].shift(1).bfill()

# 3. Features for modal fusion: solar + weather + embeddings + temporal
core_solar_cols = ["SolarGeneration"]
weather_cols = [
    "AirTemperature", "RelativeHumidity", "WindSpeed",
    "WindDirection", "ApparentTemperature", "DewPointTemperature"
]
embedding_cols = [c for c in df.columns if c.startswith("text_emb_mean_")]
temporal_cols = ["hour_sin", "hour_cos", "doy_sin", "doy_cos", "lag1"]

features = weather_cols + embedding_cols + temporal_cols

X = df[features].values
y = df["SolarGeneration"].values

# 4. Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5. Cross-validation and training
kf = KFold(n_splits=5, shuffle=False)
y_pred_full = np.zeros_like(y)
fold_metrics = []
train_times = []
model_obj = None

start_total_train = time.time()

for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    model = lgb.LGBMRegressor(
        objective="regression",
        boosting_type="gbdt",
        n_estimators=200,
        learning_rate=0.05,
        num_leaves=31,
        max_depth=7,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        verbose=-1
    )

    fold_start = time.time()
    model.fit(X_train, y_train)
    fold_end = time.time()
    train_times.append(fold_end - fold_start)

    y_pred = model.predict(X_test)
    y_pred_full[test_idx] = y_pred

    y_pred_smoothed = pd.Series(y_pred).rolling(window=3, center=True, min_periods=1).mean().values
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_smoothed))
    mae = mean_absolute_error(y_test, y_pred_smoothed)
    r2 = r2_score(y_test, y_pred_smoothed)
    print(f"Fold {fold} → RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
    fold_metrics.append((rmse, mae, r2))

    if fold == 5:
        model_obj = model

total_train_time = sum(train_times)

# 6. Supporting plots
y_pred_full_smoothed = pd.Series(y_pred_full).rolling(window=3, center=True, min_periods=1).mean().values

plt.figure(figsize=(15, 7))
plt.plot(y, label="Actual Solar Generation", color='tab:blue', alpha=0.8, linewidth=1)
plt.plot(y_pred_full_smoothed, label="Predicted Solar Generation", color='tab:orange', alpha=0.8, linewidth=1)
plt.xlabel("Time Steps")
plt.ylabel("Solar Generation")
plt.title("LightGBM Generation Prediction (Case 1: Solar + Weather)")
plt.legend()
plt.grid()
plt.tight_layout()
plt.show()

plt.figure(figsize=(7, 7))
sns.scatterplot(x=y, y=y_pred_full_smoothed, alpha=0.3)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.title("LightGBM Prediction Scatter (Case 5: Multimodal)")
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.tight_layout()
plt.show()

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_scaled)
plt.figure(figsize=(7, 6))
scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_pred_full_smoothed,
                      cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label="Predicted Solar Generation")
plt.title("LightGBM t-SNE of Predictions (Case 5: Multimodal)")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.grid(True)
plt.tight_layout()
plt.show()

errors = y - y_pred_full_smoothed
plt.figure(figsize=(8, 4))
sns.histplot(errors, kde=True, bins=70, color="orange")
plt.xlabel("Prediction Error (Actual - Predicted)")
plt.title("LightGBM Distribution of Prediction Errors (Case 5: Multimodal)")
plt.grid(True)
plt.tight_layout()
plt.show()

if "hour" in df.columns:
    df_plot = pd.DataFrame({
        "error": np.abs(y - y_pred_full_smoothed),
        "hour": df["hour"].values
    })
    plt.figure(figsize=(12, 4))
    sns.boxplot(x="hour", y="error", data=df_plot)
    plt.xlabel("Hour of Day")
    plt.ylabel("Absolute Error")
    plt.title("LightGBM Prediction Error by Hour (Case 5: Multimodal)")
    plt.tight_layout()
    plt.show()

fig = plt.figure(figsize=(6, 6))
stats.probplot(errors, dist="norm", plot=plt)
plt.title("LightGBM QQ Plot of Residuals (Case 5: Multimodal)")
plt.tight_layout()
plt.show()

# 7. Fold-wise metric summary
fold_metrics_arr = np.array(fold_metrics)
mean_rmse, mean_mae, mean_r2 = fold_metrics_arr.mean(axis=0)

print("\nFold-wise Metrics:")
for i, (rmse, mae, r2) in enumerate(fold_metrics, 1):
    print(f"Fold {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

print(f"\nAverage metrics: RMSE={mean_rmse:.4f}, MAE={mean_mae:.4f}, R2={mean_r2:.4f}")

# 8. Computational complexity
model_obj.booster_.save_model('lgb_model_case_multimodal.txt')
n_trees = model_obj.n_estimators
n_leaves = model_obj.num_leaves
params = n_trees * n_leaves
model_size_kb = os.path.getsize('lgb_model_case_multimodal.txt') / 1024

def measure_inference_time(model, X, repeat=100):
    start = time.time()
    for _ in range(repeat):
        model.predict(X)
    end = time.time()
    return (end - start) * 1000 / repeat

inference_time_ms = measure_inference_time(model_obj, X_scaled)

print(f"\nTotal Training Time (s): {total_train_time:.2f}")
print(f"Approximate Number of Parameters: {params}")
print(f"Model Size on Disk: {model_size_kb:.2f} KB")
print(f"Average Inference Time per Sample (ms): {inference_time_ms:.3f}")

print("Note: FLOPs not standardized for LightGBM; #params × timings reported as proxy.")



